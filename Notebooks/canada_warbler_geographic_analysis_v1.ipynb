{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Canada Warbler is a species of Warbler that migrates through Pennsylvania each Spring. It travels from it's wintering habitat in South America to the boreal swamps of Canada to breed. The species is of interest to birdwatchers and photographers due to its bright yellow plumage and distinct black necklace. The dataset below contains data from eBird for all Canada Warbler sightings in Pennsylvania from April 2010 to June 2020. I will use this data to map out migration patterns across the state and identify regions with the most sightings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "from pandas import Series, DataFrame\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull in .csv data file containing all Canada Warbler sighting data in Pennsylvania from April 2010 to June 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\mikea\\Documents\\Python Practice\\eBird_Geograpic_Analysis_Canada_Warbler\\Data\\canada_warbler_PA_2010_2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the data by removing spaces in headers and converting headers to lowercase, then show column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [x.lower() for x in data.columns]\n",
    "data.columns = data.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a consolidated dataframe with only the data we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_data = data[[\n",
    "    'global_unique_identifier',\n",
    "    'county', 'county_code', 'observation_count',\n",
    "    'locality', 'locality_id', 'locality_type',\n",
    "    'latitude', 'longitude', 'observation_date']].copy()\n",
    "consolidated_data.head()\n",
    "consolidated_data = consolidated_data[consolidated_data.observation_count != 'X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new columns with date specific attributes so we can filter out data more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "consolidated_data['month'] = pd.DatetimeIndex(consolidated_data['observation_date']).month\n",
    "consolidated_data['year'] = pd.DatetimeIndex(consolidated_data['observation_date']).year\n",
    "consolidated_data['week'] = pd.DatetimeIndex(consolidated_data['observation_date']).week\n",
    "consolidated_data['day'] = pd.DatetimeIndex(consolidated_data['observation_date']).day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data for May 2020. We'll create a new dataframe and add a column with geometry using geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_2020_cw_all_data = consolidated_data.query('month ==\"5\" & year ==\"2020\"')\n",
    "geographical_data_frame_may_2020 = geopandas.GeoDataFrame(\n",
    "    may_2020_cw_all_data, geometry=geopandas.points_from_xy(may_2020_cw_all_data.longitude, may_2020_cw_all_data.latitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To graph this data, we'll need to have a shape file containing geographical information for Pennsylvania. I downloaded this .shp from data.gov. This will be used to plot the background map for our data.\n",
    "\n",
    "Next, we need to know the min/max latitude and longitude values for our sightings. This will give us an idea of where our data lies on the map. Note: these don't tell us the min/max values of the state, just a general idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_map = geopandas.read_file(\"C:/Users/mikea/Documents/Python Practice/eBird_Geograpic_Analysis_Canada_Warbler/Data/tl_2016_42_cousub/tl_2016_42_cousub.shp\")\n",
    "print(geographical_data_frame_may_2020.latitude.min())\n",
    "print(geographical_data_frame_may_2020.latitude.max())\n",
    "print(geographical_data_frame_may_2020.longitude.min())\n",
    "print(geographical_data_frame_may_2020.longitude.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "state_map.plot(ax=ax, alpha=0.4,color=\"grey\")\n",
    "geographical_data_frame_may_2020.plot(column=\"day\",ax=ax,alpha=0.5, legend=True,markersize=10)\n",
    "plt.title(\"May 2020 Canada Warbler Sighting Locations by Day of the Month\", fontsize=15,fontweight=\"bold\")\n",
    "plt.xlim(-81,-74.5)\n",
    "plt.ylim( 39.5,42.8)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a bubble map with points with varying marker sizes by count per day at a given location, we need to create a column from the geometry column so a .count() function can be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geographical_data_frame_may_2020['geometry_str'] = geographical_data_frame_may_2020.geometry.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create a new dataframe grouped by coordinates with a count of sightings at each coordinate for all of May."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_2020_count_per_location = geographical_data_frame_may_2020.groupby([\n",
    "    \"geometry_str\", \"locality\", \"latitude\", \"longitude\", \"county\", \"county_code\"\n",
    "    ]).size().reset_index(name=\"sighting_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert the geometry_str column back into a geopandas geometry, we'll do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "\n",
    "may_2020_count_per_location[\"coordinates\"] = may_2020_count_per_location[\"geometry_str\"].apply(wkt.loads)\n",
    "gdf_may_2020_count_per_location = geopandas.GeoDataFrame(may_2020_count_per_location, geometry=\"coordinates\")\n",
    "gdf_may_2020_count_per_location = gdf_may_2020_count_per_location.drop(columns=[\"geometry_str\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use a bubble plot with marker size set to the count of sightings at each location. This gives us an idea of where some of the best hotspots in the state for Canada Warbler are, at a very high level view anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,16))\n",
    "state_map.plot(ax=ax, alpha=0.4,color=\"grey\")\n",
    "gdf_may_2020_count_per_location.plot(\n",
    "    ax=ax,color=\"#07424A\", markersize=\"sighting_count\",alpha=0.9, categorical=False, legend=True )\n",
    "plt.xlim(-81,-74.5)\n",
    "plt.ylim( 39.5,42.8)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to create an interactive visualization, where the number of sightings also has a color component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_may_2020_count_per_location['coordinates'] = gdf_may_2020_count_per_location['coordinates'].centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(\n",
    "    gdf_may_2020_count_per_location, \n",
    "        lat=\"latitude\", \n",
    "                        lon=\"longitude\", color=\"sighting_count\", size=\"sighting_count\", hover_name=\"locality\", zoom=5.8)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of doing analysis for only May 2020, would be more inightful to have an interactive plot with a time scroller. To do this, I'll create a new gdf dataframe from the initial 'consolidated_data' dataframe, but this time I won't filter by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cw_all_data = geopandas.GeoDataFrame(\n",
    "    consolidated_data, geometry=geopandas.points_from_xy(consolidated_data.longitude, consolidated_data.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cw_all_data['geometry_str'] = gdf_cw_all_data.geometry.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cw_all_data_grouped = gdf_cw_all_data.groupby([\"geometry_str\", \"locality\", \"latitude\", \"longitude\", \"county\", \"county_code\", \"observation_date\"]).size().reset_index(name=\"sighting_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cw_all_data_grouped[\"coordinates\"] = gdf_cw_all_data_grouped[\"geometry_str\"].apply(wkt.loads)\n",
    "gdf_cw_all_data_grouped = geopandas.GeoDataFrame(gdf_cw_all_data_grouped, geometry=\"coordinates\")\n",
    "gdf_cw_all_data_grouped['observation_date'] = pd.to_datetime(gdf_cw_all_data_grouped['observation_date'].str.strip(), format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cw_all_data_grouped['observation_date'] = gdf_cw_all_data_grouped['observation_date'].dt.strftime('%Y/%m/%d')\n",
    "gdf_cw_all_data_by_date = gdf_cw_all_data_grouped.iloc[gdf_cw_all_data_grouped.observation_date.sort_values().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = gdf_cw_all_data_by_date.observation_date.min()\n",
    "max_date = gdf_cw_all_data_by_date.observation_date.max()\n",
    "\n",
    "fig = px.scatter_mapbox(gdf_cw_all_data_by_date, \n",
    "                 lat=\"latitude\", lon=\"longitude\", animation_frame=\"observation_date\",\n",
    "            size=\"sighting_count\", color=\"sighting_count\", hover_name=\"locality\", range_color = (0,20),\n",
    "           zoom = 5.8)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(xaxis = {'type' : 'date'})\n",
    "fig.update_layout(xaxis = {'dtick' : 86400000.0 * 30})\n",
    "fig.update_layout(legend= {'itemsizing': 'constant'})\n",
    "fig.update_layout(transition = {'duration': 30})\n",
    "fig.update_xaxes(range=[min_date, max_date])\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a Choropleth map!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maps I build below will represent the number of Canada Warbler sightings per county by year, so I'll start by creating a column only containing the year portion of the observation dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cw_all_data_by_date['observation_date'] = pd.to_datetime(gdf_cw_all_data_by_date['observation_date'])\n",
    "gdf_cw_all_data_by_date['observation_year'] = gdf_cw_all_data_by_date['observation_date'].dt.strftime('%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've pulled in data from the Homeland Infrastructure Foundation for all of the FIPS codes in Pennsylvania. As with any other .csv file, I perform some basic clean-up steps to tidy up the column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_data = pd.read_csv(r'C:\\Users\\mikea\\Documents\\Python Practice\\eBird_Geograpic_Analysis_Canada_Warbler\\Data\\fips_codes_PA.csv')\n",
    "fips_data.columns = [x.lower() for x in fips_data.columns]\n",
    "fips_data.columns = fips_data.columns.str.replace(' ', '_')\n",
    "fips_data = fips_data.rename(columns={\"short_county_name\": \"county\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state code (42) is in a separate column than the county codes (3-digits). Since the the geojson file we'll be working with requires the 5-digit FIPS codes to plot the maps, I'll need to concatenate. Pandas removed the leading zeroes from the county FIPs codes, so the first line of code below fills in as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_data['county_fips_code'] = fips_data['county_fips_code'].apply(lambda x: '{0:0>3}'.format(x))\n",
    "fips_data['state_fips_code'] = fips_data['state_fips_code'].astype(str)\n",
    "fips_data[\"full_fips_code\"] = fips_data[\"state_fips_code\"] + fips_data[\"county_fips_code\"]\n",
    "fips_data = fips_data.set_index(\"county\")\n",
    "fips_data = fips_data.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll create a small dataframe by dissolving (aka aggregating) data in the gdf_cw_all_data_by_date dataframe by county, county code, and observation year. This will sum up the sighting counts for unique sightings in each county by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_county = gdf_cw_all_data_by_date.dissolve(by = ['county_code', 'county', 'observation_year'], aggfunc = 'sum')\n",
    "data_by_county = data_by_county.drop(columns=[\"longitude\", \"latitude\"])\n",
    "data_by_county = data_by_county.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot this data, we'll first need to merge the dataframe containing the FIPS code with the aggregated dataframe containing the bird sightings. To do this, I create a new dataframe containing only FIPS info and county name to prepare for the merge. I will be joining on the name of the county. I noticed while joining that some FIPS codes were showing as NaN after the merge and discovered this was due to white space in the FIPS dataframe. The third line of code removes the white space causing the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_to_merge = fips_data['full_fips_code']\n",
    "fips_to_merge = fips_to_merge.reset_index()\n",
    "fips_to_merge['county'] = fips_to_merge['county'].str.strip() #for some reason the fips file had whitespaces, leading to NaN in merge for some counties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataframes can be merged. To do this we'll use an outer join on the 'county' column.\n",
    "\n",
    "We need to sort by 'year' here so that any time series animated visualizations display in the proper order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_by_county = pd.merge(data_by_county, fips_to_merge, how='outer', on=['county'])\n",
    "merged_data_by_county['sighting_count'] = merged_data_by_county['sighting_count'].astype(float)\n",
    "merged_data_by_county = merged_data_by_county.sort_values(by=['observation_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Plotly Express requires a geojson file to create a map. We'll use the urlopen module from the urllib.request package the json package to bring in a file containin all county FIPS codes in the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "with urlopen(\"https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json\") as response:\n",
    " counties = json.load(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot this out for a single year, as shown below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(merged_data_by_county.query(\"observation_year == '2011'\"), geojson=counties, locations=\"full_fips_code\", color=\"sighting_count\",\n",
    " color_continuous_scale=\"spectral\",\n",
    " range_color=(1, 150),\n",
    " scope=\"usa\",\n",
    " labels={\"sighting_count\":\"sighting_count\"}\n",
    " )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.update_geos(fitbounds=\"locations\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better yet, we can create an animated time-series visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(merged_data_by_county, geojson=counties, locations=\"full_fips_code\", color=\"sighting_count\",\n",
    " color_continuous_scale=\"spectral\",\n",
    " animation_frame = \"observation_year\",\n",
    " range_color=(1, 180),\n",
    " scope=\"usa\",\n",
    " labels={\"sighting_count\":\"sighting_count\"},\n",
    " hover_name=\"county\"\n",
    " )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.update_geos(fitbounds=\"locations\")\n",
    "fig.update_layout(transition = {\"duration\": 1000})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
